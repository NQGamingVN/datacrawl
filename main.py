import requests
import os
import time
import psycopg2
from datetime import datetime, timedelta
from flask import Flask, render_template_string, request, jsonify, Response
import threading
import json
import zipfile
from io import BytesIO

API_URL = "https://wtx.tele68.com/v1/tx/sessions"
INTERVAL = 3600
RETRY_INTERVAL = 300
MAX_RETRIES = 5

# ====== K·∫æT N·ªêI DB ======
def get_conn():
    dsn = os.getenv("DATABASE_URL")
    if not dsn:
        raise ValueError("‚ùå DATABASE_URL ch∆∞a ƒë∆∞·ª£c set trong environment")
    if "sslmode" not in dsn:
        if "?" in dsn:
            dsn += "&sslmode=require"
        else:
            dsn += "?sslmode=require"

    retries = 5
    for i in range(retries):
        try:
            conn = psycopg2.connect(dsn)
            print("‚úÖ K·∫øt n·ªëi database th√†nh c√¥ng")
            return conn
        except Exception as e:
            print(f"‚ùå K·∫øt n·ªëi DB th·∫•t b·∫°i ({i+1}/{retries}): {e}")
            time.sleep(5)
    raise Exception("Kh√¥ng th·ªÉ k·∫øt n·ªëi database sau nhi·ªÅu l·∫ßn retry")

def init_db():
    conn = get_conn()
    cur = conn.cursor()
    cur.execute("""
    CREATE TABLE IF NOT EXISTS sessions (
        id BIGINT PRIMARY KEY,
        dice1 INT,
        dice2 INT,
        dice3 INT,
        point INT,
        result TEXT
    )
    """)
    conn.commit()
    cur.close()
    conn.close()

# ====== L∆ØU DB ======
def save_to_db(new_sessions):
    conn = get_conn()
    cur = conn.cursor()
    for s in new_sessions:
        try:
            cur.execute("""
                INSERT INTO sessions (id, dice1, dice2, dice3, point, result)
                VALUES (%s, %s, %s, %s, %s, %s)
                ON CONFLICT (id) DO NOTHING
            """, (s["id"], s["dices"][0], s["dices"][1], s["dices"][2],
                  s["point"], s["resultTruyenThong"]))
        except Exception as e:
            print("‚ùå L·ªói insert:", e)
    conn.commit()
    cur.close()
    conn.close()

# ====== FETCH & SAVE V·ªöI RETRY ======
def fetch_and_save_with_retry():
    """Fetch v√† save d·ªØ li·ªáu v·ªõi retry mechanism"""
    for attempt in range(MAX_RETRIES):
        try:
            print(f"üîÑ B·∫Øt ƒë·∫ßu fetch d·ªØ li·ªáu (l·∫ßn {attempt + 1}/{MAX_RETRIES})...")
            
            resp = requests.get(API_URL, timeout=60)
            data = resp.json()

            if "list" not in data:
                print("‚ö†Ô∏è API kh√¥ng tr·∫£ v·ªÅ d·ªØ li·ªáu h·ª£p l·ªá")
                continue

            sessions = data["list"]
            sessions.sort(key=lambda x: x["id"])
            save_to_db(sessions)

            print(f"[{datetime.now()}] ‚úÖ Fetch th√†nh c√¥ng! ƒê√£ l∆∞u {len(sessions)} phi√™n "
                  f"(ID {sessions[0]['id']} ‚Üí {sessions[-1]['id']})")
            return len(sessions)

        except requests.exceptions.RequestException as e:
            print(f"‚ùå L·ªói m·∫°ng/API l·∫ßn {attempt + 1}/{MAX_RETRIES}: {e}")
        except Exception as e:
            print(f"‚ùå L·ªói kh√¥ng x√°c ƒë·ªãnh l·∫ßn {attempt + 1}/{MAX_RETRIES}: {e}")
        
        if attempt < MAX_RETRIES - 1:
            print(f"‚è≥ Ch·ªù {RETRY_INTERVAL} gi√¢y tr∆∞·ªõc khi th·ª≠ l·∫°i fetch...")
            time.sleep(RETRY_INTERVAL)
        else:
            print("üö´ ƒê√£ th·ª≠ fetch t·ªëi ƒëa s·ªë l·∫ßn, chuy·ªÉn sang chu k·ª≥ ti·∫øp theo")
    
    return 0

# ====== CHU·ªñI LI√äN T·ª§C ======
def get_continuous_chunks():
    """L·∫•y c√°c chu·ªói d·ªØ li·ªáu li√™n t·ª•c (kh√¥ng b·ªã ƒë·ª©t)"""
    conn = get_conn()
    cur = conn.cursor()
    
    cur.execute("SELECT id FROM sessions ORDER BY id")
    all_ids = [row[0] for row in cur.fetchall()]
    
    if not all_ids:
        return []
    
    chunks = []
    current_chunk = [all_ids[0]]
    
    for i in range(1, len(all_ids)):
        if all_ids[i] == all_ids[i-1] + 1:
            current_chunk.append(all_ids[i])
        else:
            chunks.append(current_chunk)
            current_chunk = [all_ids[i]]
    
    chunks.append(current_chunk)
    cur.close()
    conn.close()
    return chunks

# ====== QU·∫¢N L√ù D·ªÆ LI·ªÜU ======
def delete_session(session_id):
    """X√≥a m·ªôt phi√™n c·ª• th·ªÉ"""
    conn = get_conn()
    cur = conn.cursor()
    try:
        cur.execute("DELETE FROM sessions WHERE id = %s", (session_id,))
        conn.commit()
        return True
    except Exception as e:
        print(f"‚ùå L·ªói x√≥a phi√™n {session_id}: {e}")
        return False
    finally:
        cur.close()
        conn.close()

def delete_sessions_range(start_id, end_id):
    """X√≥a c√°c phi√™n trong kho·∫£ng"""
    conn = get_conn()
    cur = conn.cursor()
    try:
        cur.execute("DELETE FROM sessions WHERE id BETWEEN %s AND %s", (start_id, end_id))
        count = cur.rowcount
        conn.commit()
        return count
    except Exception as e:
        print(f"‚ùå L·ªói x√≥a phi√™n {start_id}-{end_id}: {e}")
        return 0
    finally:
        cur.close()
        conn.close()

def search_session(session_id):
    """T√¨m ki·∫øm phi√™n theo ID"""
    conn = get_conn()
    cur = conn.cursor()
    try:
        cur.execute("SELECT id, dice1, dice2, dice3, point, result FROM sessions WHERE id = %s", (session_id,))
        session = cur.fetchone()
        return session
    except Exception as e:
        print(f"‚ùå L·ªói t√¨m ki·∫øm phi√™n {session_id}: {e}")
        return None
    finally:
        cur.close()
        conn.close()

# ====== STATISTICS FUNCTIONS ======
def get_statistics():
    """L·∫•y th·ªëng k√™ d·ªØ li·ªáu - LU√îN L√ÄM M·ªöI KHI G·ªåI"""
    conn = get_conn()
    if not conn:
        return None
    
    cur = conn.cursor()
    stats = {}
    
    try:
        # T·ªïng s·ªë phi√™n
        cur.execute("SELECT COUNT(*) FROM sessions")
        stats['total_sessions'] = cur.fetchone()[0]
        
        # Phi√™n ƒë·∫ßu ti√™n v√† cu·ªëi c√πng
        cur.execute("SELECT id, dice1, dice2, dice3, point, result FROM sessions ORDER BY id ASC LIMIT 1")
        stats['first_session'] = cur.fetchone()
        
        cur.execute("SELECT id, dice1, dice2, dice3, point, result FROM sessions ORDER BY id DESC LIMIT 1")
        stats['last_session'] = cur.fetchone()
        
        # Phi√™n tr√πng
        cur.execute("SELECT id, COUNT(*) FROM sessions GROUP BY id HAVING COUNT(*) > 1")
        stats['duplicate_sessions'] = cur.fetchall()
        
        # Phi√™n thi·∫øu
        cur.execute("""
            WITH gaps AS (
                SELECT id, LAG(id) OVER (ORDER BY id) as prev_id
                FROM sessions
            )
            SELECT prev_id + 1 as missing_start, id - 1 as missing_end,
                   id - prev_id - 1 as missing_count
            FROM gaps WHERE id - prev_id > 1
            ORDER BY missing_start
        """)
        stats['missing_sessions'] = cur.fetchall()
        
        # D·ªØ li·ªáu m·ªõi nh·∫•t (20 phi√™n)
        cur.execute("""
            SELECT id, dice1, dice2, dice3, point, result
            FROM sessions ORDER BY id DESC LIMIT 20
        """)
        stats['recent_sessions'] = cur.fetchall()
        
        # Th·ªëng k√™ chu·ªói li√™n t·ª•c
        chunks = get_continuous_chunks()
        stats['continuous_chunks'] = len(chunks)
        stats['chunks_info'] = []
        for i, chunk in enumerate(chunks[:10]):
            if chunk:
                stats['chunks_info'].append({
                    'name': f'data{i+1}',
                    'start': chunk[0],
                    'end': chunk[-1],
                    'count': len(chunk)
                })
        
        # Th·ªùi gian c·∫≠p nh·∫≠t
        stats['last_updated'] = datetime.now().strftime("%H:%M:%S %d/%m/%Y")
        next_fetch = datetime.now() + timedelta(hours=1)
        stats['next_fetch'] = next_fetch.strftime("%H:%M:%S")
        
    except Exception as e:
        print(f"‚ùå L·ªói khi th·ªëng k√™: {e}")
        stats['error'] = str(e)
    finally:
        cur.close()
        conn.close()
    
    return stats

# ====== XU·∫§T FILE TO√ÄN B·ªò ======
def export_full_txt():
    """Xu·∫•t file TXT to√†n b·ªô"""
    conn = get_conn()
    if not conn:
        return "‚ùå L·ªói k·∫øt n·ªëi database", 500
    
    cur = conn.cursor()
    try:
        cur.execute("SELECT id, dice1, dice2, dice3, point, result FROM sessions ORDER BY id ASC")
        rows = cur.fetchall()
        
        if not rows:
            return "‚ùå Kh√¥ng c√≥ d·ªØ li·ªáu ƒë·ªÉ xu·∫•t", 404
        
        filename = f"tx_data_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt"
        content = ""
        for row in rows:
            issue_id, dice1, dice2, dice3, point, result_text = row
            content += f"{issue_id}|{dice1}:{dice2}:{dice3}|{point}|{result_text}\n"
        
        return Response(
            content,
            mimetype="text/plain",
            headers={"Content-Disposition": f"attachment;filename={filename}"}
        )
        
    except Exception as e:
        return f"‚ùå L·ªói khi xu·∫•t file TXT: {e}", 500
    finally:
        cur.close()
        conn.close()

def export_full_json():
    """Xu·∫•t file JSON to√†n b·ªô"""
    conn = get_conn()
    if not conn:
        return "‚ùå L·ªói k·∫øt n·ªëi database", 500
    
    cur = conn.cursor()
    try:
        cur.execute("SELECT id, dice1, dice2, dice3, point, result FROM sessions ORDER BY id ASC")
        rows = cur.fetchall()
        
        if not rows:
            return "‚ùå Kh√¥ng c√≥ d·ªØ li·ªáu ƒë·ªÉ xu·∫•t", 404
        
        data = []
        for row in rows:
            issue_id, dice1, dice2, dice3, point, result_text = row
            data.append({
                "id": issue_id,
                "dice1": dice1,
                "dice2": dice2,
                "dice3": dice3,
                "point": point,
                "result": result_text
            })
        
        filename = f"tx_data_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        
        return Response(
            json.dumps(data, ensure_ascii=False, indent=2),
            mimetype="application/json",
            headers={"Content-Disposition": f"attachment;filename={filename}"}
        )
        
    except Exception as e:
        return f"‚ùå L·ªói khi xu·∫•t file JSON: {e}", 500
    finally:
        cur.close()
        conn.close()

# ====== XU·∫§T FILE THEO CHU·ªñI LI√äN T·ª§C ======
def export_continuous_chunks_txt():
    """Xu·∫•t nhi·ªÅu file TXT theo chu·ªói li√™n t·ª•c"""
    conn = get_conn()
    if not conn:
        return "‚ùå L·ªói k·∫øt n·ªëi database", 500
    
    try:
        chunks = get_continuous_chunks()
        
        if not chunks:
            return "‚ùå Kh√¥ng c√≥ d·ªØ li·ªáu ƒë·ªÉ xu·∫•t", 404
        
        zip_buffer = BytesIO()
        with zipfile.ZipFile(zip_buffer, 'w', zipfile.ZIP_DEFLATED) as zip_file:
            for i, chunk in enumerate(chunks):
                if len(chunk) > 0:
                    cur = conn.cursor()
                    placeholders = ','.join(['%s'] * len(chunk))
                    cur.execute(f"""
                        SELECT id, dice1, dice2, dice3, point, result 
                        FROM sessions 
                        WHERE id IN ({placeholders}) 
                        ORDER BY id
                    """, chunk)
                    rows = cur.fetchall()
                    cur.close()
                    
                    content = ""
                    for row in rows:
                        issue_id, dice1, dice2, dice3, point, result_text = row
                        content += f"{issue_id}|{dice1}:{dice2}:{dice3}|{point}|{result_text}\n"
                    
                    filename = f"data{i+1}.txt"
                    zip_file.writestr(filename, content)
        
        zip_buffer.seek(0)
        
        return Response(
            zip_buffer.getvalue(),
            mimetype="application/zip",
            headers={"Content-Disposition": "attachment;filename=tx_data_continuous.zip"}
        )
        
    except Exception as e:
        return f"‚ùå L·ªói khi xu·∫•t file: {e}", 500
    finally:
        conn.close()

def export_continuous_chunks_json():
    """Xu·∫•t nhi·ªÅu file JSON theo chu·ªói li√™n t·ª•c"""
    conn = get_conn()
    if not conn:
        return "‚ùå L·ªói k·∫øt n·ªëi database", 500
    
    try:
        chunks = get_continuous_chunks()
        
        if not chunks:
            return "‚ùå Kh√¥ng c√≥ d·ªØ li·ªáu ƒë·ªÉ xu·∫•t", 404
        
        zip_buffer = BytesIO()
        with zipfile.ZipFile(zip_buffer, 'w', zipfile.ZIP_DEFLATED) as zip_file:
            for i, chunk in enumerate(chunks):
                if len(chunk) > 0:
                    cur = conn.cursor()
                    placeholders = ','.join(['%s'] * len(chunk))
                    cur.execute(f"""
                        SELECT id, dice1, dice2, dice3, point, result 
                        FROM sessions 
                        WHERE id IN ({placeholders}) 
                        ORDER BY id
                    """, chunk)
                    rows = cur.fetchall()
                    cur.close()
                    
                    data = []
                    for row in rows:
                        issue_id, dice1, dice2, dice3, point, result_text = row
                        data.append({
                            "id": issue_id,
                            "dice1": dice1,
                            "dice2": dice2,
                            "dice3": dice3,
                            "point": point,
                            "result": result_text
                        })
                    
                    filename = f"data{i+1}.json"
                    zip_file.writestr(filename, json.dumps(data, ensure_ascii=False, indent=2))
        
        zip_buffer.seek(0)
        
        return Response(
            zip_buffer.getvalue(),
            mimetype="application/zip",
            headers={"Content-Disposition": "attachment;filename=tx_data_continuous.zip"}
        )
        
    except Exception as e:
        return f"‚ùå L·ªói khi xu·∫•t file: {e}", 500
    finally:
        conn.close()

# ====== FLASK WEB APP ======
app = Flask(__name__)

# HTML Template - ƒê√É S·ª¨A L·∫†I CHO TX
HTML_TEMPLATE = '''
<!DOCTYPE html>
<html lang="vi">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>üé≤ Qu·∫£n L√Ω D·ªØ Li·ªáu TX</title>
    <style>
        /* CSS gi·ªØ nguy√™n */
    </style>
</head>
<body>
    <div class="container">
        <div class="header">
            <h1>üé≤ Qu·∫£n L√Ω D·ªØ Li·ªáu TX</h1>
            <p>Thu th·∫≠p, qu·∫£n l√Ω v√† ph√¢n t√≠ch d·ªØ li·ªáu phi√™n ch∆°i TX</p>
        </div>

        <!-- C√°c ph·∫ßn c√≤n l·∫°i gi·ªØ nguy√™n, nh∆∞ng ƒê·∫¢M B·∫¢O d√πng table "sessions" ch·ª© kh√¥ng ph·∫£i "sessions_new" -->
    </div>
</body>
</html>
'''

@app.route("/")
def home():
    stats = get_statistics()
    return render_template_string(HTML_TEMPLATE, stats=stats)

@app.route("/health")
def health():
    return "OK"

# ====== API QU·∫¢N L√ù ======
@app.route("/api/session/<int:session_id>")
def api_get_session(session_id):
    """API l·∫•y th√¥ng tin phi√™n"""
    session = search_session(session_id)
    if session:
        return jsonify({"success": True, "session": session})
    else:
        return jsonify({"success": False, "error": "Kh√¥ng t√¨m th·∫•y phi√™n"})

@app.route("/api/delete/<int:session_id>", methods=["DELETE"])
def api_delete_session(session_id):
    """API x√≥a phi√™n"""
    success = delete_session(session_id)
    if success:
        return jsonify({"success": True, "message": f"ƒê√£ x√≥a phi√™n {session_id}"})
    else:
        return jsonify({"success": False, "error": "L·ªói khi x√≥a phi√™n"})

@app.route("/api/delete-range/<int:start_id>/<int:end_id>", methods=["DELETE"])
def api_delete_sessions_range(start_id, end_id):
    """API x√≥a kho·∫£ng phi√™n"""
    deleted_count = delete_sessions_range(start_id, end_id)
    if deleted_count > 0:
        return jsonify({"success": True, "deleted_count": deleted_count})
    else:
        return jsonify({"success": False, "error": "L·ªói khi x√≥a kho·∫£ng phi√™n"})

@app.route("/api/manual-fetch", methods=["POST"])
def api_manual_fetch():
    """API fetch d·ªØ li·ªáu th·ªß c√¥ng"""
    try:
        saved_count = fetch_and_save_with_retry()
        return jsonify({"success": True, "saved_count": saved_count})
    except Exception as e:
        return jsonify({"success": False, "error": str(e)})

# ====== API XU·∫§T FILE ======
@app.route("/export/txt")
def export_txt():
    return export_full_txt()

@app.route("/export/json")
def export_json():
    return export_full_json()

@app.route("/export/continuous-txt")
def export_continuous_txt():
    return export_continuous_chunks_txt()

@app.route("/export/continuous-json")
def export_continuous_json():
    return export_continuous_chunks_json()

@app.route("/api/data")
def api_data():
    stats = get_statistics()
    return jsonify(stats)

# ====== V√íNG L·∫∂P CH√çNH ======
def loop_task():
    while True:
        try:
            init_db()
            saved_count = fetch_and_save_with_retry()
            if saved_count > 0:
                print(f"‚úÖ ƒê√£ thu th·∫≠p th√†nh c√¥ng {saved_count} phi√™n m·ªõi")
            else:
                print("‚ö†Ô∏è Kh√¥ng c√≥ phi√™n m·ªõi n√†o ƒë∆∞·ª£c thu th·∫≠p")
        except Exception as e:
            print(f"[{datetime.now()}] ‚ö†Ô∏è L·ªói trong loop_task: {e}")
        print(f"‚è≥ Ch·ªù {INTERVAL} gi√¢y...\n")
        time.sleep(INTERVAL)

if __name__ == "__main__":
    t = threading.Thread(target=loop_task, daemon=True)
    t.start()
    port = int(os.environ.get("PORT", 10000))
    app.run(host="0.0.0.0", port=port)
